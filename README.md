# ğŸ¤– Gestureâ€‘Controlled Wiâ€‘Fi Robot with Obstacle Avoidance & Live Telemetry

Control an ESP32â€‘powered robot using **hand gestures** with **OpenCV + MediaPipe**, sent wirelessly over **UDP Wiâ€‘Fi**.
Two operation modes are supported:

| Mode | Directory | Description |
|------|----------|-------------|
| âœ… **Without Live Plotter** | `/Without_Live_Plotter` | Pure gesture control with obstacle avoidance |
| ğŸ“Š **With Live Plotter** | `/With_Live_Plotter` | Gesture control **+ realâ€‘time motion & ultrasonic plotting** |

---

## âœ¨ Key Features

| Capability | Details |
|-----------|--------|
ğŸ¯ **Realâ€‘time gesture recognition** | Track hand landmarks to send drive commands
ğŸ“¶ **Wiâ€‘Fi UDP control** | Laptop â†’ ESP32, fast lowâ€‘latency commands
ğŸ›‘ **Automatic obstacle avoidance** | Ultrasonic braking + autoâ€‘halt logic
ğŸ“ˆ **Live plotting mode** | Track movement + distance in realâ€‘time (matplotlib)
ğŸ§  **Clean modular repo** | Separated folders for easier navigation
ğŸ” **Telemetry feedback** | Robot reports movement + sensor values
ğŸ› ï¸ **MicroPython firmware** | Lightweight & fast on ESP32

> The bot moves **Forward, Backward, Left, Right, Stop** based on gesture recognition.

---

## ğŸ“‚ Repository Structure

```
ğŸ“ Gestureâ€‘Controlledâ€‘Bot/
â”œâ”€â”€ ğŸ“ With_Live_Plotter/
â”‚   â”œâ”€â”€ esp32_wlp.py
â”‚   â”œâ”€â”€ lap_gest_wlp.py
â”‚   â””â”€â”€ live_plotter.py
â”‚
â””â”€â”€ ğŸ“ Without_Live_Plotter/
    â”œâ”€â”€ lap_gest.py
    â””â”€â”€ esp32.py
```

---

## ğŸ§  System Architecture

Laptop Camera â†’ MediaPipe Gesture Detection â†’ UDP Packets â†’ ESP32 Motor PWM â†’ Robot Movement
& in live mode â†’ Telemetry â†’ PC â†’ **Live Graph**

---

## ğŸ› ï¸ Hardware Reference

| Component | Usage |
|----------|-------|
ESP32 | Wiâ€‘Fi + motor control + ultrasonic
L298N/Hâ€‘Bridge | Motor driver
Ultrasonic HCâ€‘SR04 | Obstacle detection
Laptop Camera | Gesture input

### âš™ï¸ ESP32 Pin Map
| Function | Pin |
|---------|----|
Motor PWM | GPIO 25, 33
Motor Dir | 26, 27, 14, 12
Ultrasonic | TRIG=5, ECHO=18

---

## ğŸ“¡ Network & Config

| Setting | Value |
|--------|-------|
AP SSID | `ESP32-GestureBot`
Password | `12345678`
ESP32 IP | `192.168.4.1`
Laptop UDP target | `4210`
Telemetry (live mode) | Port `5000` to laptop IP

---

## ğŸš€ Setup

### 1ï¸âƒ£ Install PC Requirements
```bash
pip install -r requirements.txt
# Recommanded ---> Python 3.11
```

### 2ï¸âƒ£ Flash ESP32 (MicroPython)

Choose the mode folder:

âœ… Without live plot â†’ `esp32.py`

ğŸ“Š With live plot â†’ set your PC IP in `esp32_wlp.py` then upload

---

## â–¶ï¸ Run

### **Without Live Plot**
```bash
cd Without_Live_Plotter
python lap_gest.py
```

### **With Live Plot**
```bash
cd With_Live_Plotter
python live_plotter.py     # start logger first
python lap_gest_wlp.py
```

> Robot begins responding to gestures immediately. Press `Esc` to exit.

---

## ğŸ“Š Telemetry Format
```
<COMMAND>,<DIST_CM>,<TIMESTAMP_MS>

Example:
F,22,18992
OBSTACLE,9,19020
```

---

## ğŸ§© Future Enhancements Ideas
- Add Web UI dashboard (Flask)
- Train ML model for gesture instead of heuristics
- Add wheel encoders for accurate path mapping
- Deploy on Raspberry Pi + ESPâ€‘Now mesh variant

---

## ğŸ’¡ Tips
âœ… Use good lighting for gesture detection

âœ… Ensure PC connected to ESP32 Wiâ€‘Fi

âœ… Test robot on support before ground runs

---

## ğŸ… Credits
- MediaPipe & OpenCV for gesture tracking
- MicroPython community for ESP32 control patterns

---
